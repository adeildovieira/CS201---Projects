import java.util.*;

/**
 * Implements the MarkovInterface to generate random text based
 * on a training text. Searches over training text to generate
 * each random word of generated text.
 * For use in Compsci 201, Fall 2022, Duke University
 * @author Adeildo Vieira Silva Neto (av259)
 * @author Brandon Fain
 */

 public class BaseMarkov implements MarkovInterface {
	
	protected String[] myWords;		// Training text split into array of words 
	protected Random myRandom;		// Random number generator
	protected int myOrder;			// Length of WordGrams used
	
	/**
	 * Default constructor creates order 2 model
	 */
	public BaseMarkov() {
		this(2);
	}


	/**
	 * Initializes a model of given order and random number generator.
	 * @param order Number of words used to generate next 
	 * random word / size of WordGrams used.
	 */
	public BaseMarkov(int order){
		myOrder = order;
		myRandom = new Random();
	}
	

	/**
	 * Initializes training text. Should always be called prior to
	 * random text generation.
	 */
	@Override
	// Time Complexity: O(n)
	public void setTraining(String text){
		myWords = text.split("\\s+");
	}


	/**
	 * Get a list of Strings containing all words that follow
	 * from wgram in the training text. Result may be an empty list.
	 * Implemented by looping over training text.
	 * @param wgram is a WordGram to search for in the text
	 * @return List of words following wgram in training text.
	 * May be empty.
	 */
	@Override
	// Time Complexity: O(n^2)
	public List<String> getFollows(WordGram wgram) {
		List<String> follows = new ArrayList<>();
		WordGram currentWG = new WordGram(myWords,0,wgram.length());
		for (int i = wgram.length(); i < myWords.length; i += 1) {
			String currentWord = myWords[i];
			if (currentWG.equals(wgram)) {
				follows.add(currentWord);
			}
			currentWG = currentWG.shiftAdd(currentWord);
		}
		return follows;
	}


	/**
	 * Returns a random word that follows kGram in the training text.
	 * In case no word follows kGram, returns a random word from the
	 * entire training text.
	 * @param wgram is being searched for in training text. Typically
	 * the previous words of the randomly generated text, but could be
	 * an arbitrary WordGram.
	 * @return a random word among those that follow after kGram in 
	 * the training text, or a random word from the training text.
	 */
	// Time Complexity: O(n)
	private String getNext(WordGram wgram) {
		List<String> follows = getFollows(wgram); //1, O(n)
		if (follows.size() == 0) { //1, O(1)
			int randomIndex = myRandom.nextInt(myWords.length); //1, O(1)
			follows.add(myWords[randomIndex]); //1, O(N)
		}
		int randomIndex = myRandom.nextInt(follows.size()); //1, O(1)
		return follows.get(randomIndex); //1, O(1)
	}


	/**
	 * Generates length random words based on training text.
	 * Initial words are a random WordGram taken from the training text.
	 * Subsequent words are generated by calling getNext on the current
	 * WordGram, which is then shifted to include the newly generated 
	 * word at the end. Words are separated by spaces in returned string.
	 * @param length Number of words to generate
	 * @returns length randomly generated words using Markov model, 
	 * separated by spaces
	 */
	@Override
	// Time Complexity: O(n^2)
	public String getRandomText(int length){
		ArrayList<String> randomWords = new ArrayList<>(length); // 1, O(1)
		int index = myRandom.nextInt(myWords.length - myOrder + 1); // 1, O(1)
		WordGram current = new WordGram(myWords,index,myOrder); // 1, O(1)
		randomWords.add(current.toString()); // 1, O(n)

		for(int k=0; k < length-myOrder; k += 1) { // n, O(1)
			String nextWord = getNext(current); // n, O(n)
			randomWords.add(nextWord); // n, O(1)
			current = current.shiftAdd(nextWord); // n, O(1)
		}
		return String.join(" ", randomWords); //1, O(1)
	}

	/**
	 * Returns order of Markov model = the length of
	 * WordGrams used.
	 */
	@Override
	public int getOrder() { // myorder return (OK tested)
		return myOrder;
	}

	/**
	 * Sets the seed of the random number generator
	 * Model will return same value when called with 
	 * same training text after same seed set.
	 * @param seed Random number generator seed
	 */
	@Override
	public void setSeed(long seed) {
		myRandom.setSeed(seed);
	}
}